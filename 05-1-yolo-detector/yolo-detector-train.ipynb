{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8aaf6e3",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e8aaf6e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "V2Jxxsz3ET_N"
      },
      "id": "V2Jxxsz3ET_N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fake wandb (used by YOLOv3 implementation but not needed now)\n",
        "!echo \"def log(data=None, step=None):\" > wandb.py\n",
        "!echo \"    pass\" >> wandb.py\n",
        "!echo \"def init(config=None, project=None, name=None):\" >> wandb.py\n",
        "!echo \"    pass\" >> wandb.py\n",
        "!echo \"def finish():\" >> wandb.py\n",
        "!echo \"    pass\" >> wandb.py\n",
        "import wandb"
      ],
      "metadata": {
        "id": "fIqUPboMLkvz"
      },
      "id": "fIqUPboMLkvz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone YOLOv3 implemementation\n",
        "!git clone https://github.com/Lornatang/YOLOv3-PyTorch.git"
      ],
      "metadata": {
        "id": "cB1sM_csyPG-"
      },
      "id": "cB1sM_csyPG-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls YOLOv3-PyTorch"
      ],
      "metadata": {
        "id": "HO4el0hVyV3U"
      },
      "id": "HO4el0hVyV3U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install YOLOv3\n",
        "!ln -sf YOLOv3-PyTorch/yolov3_pytorch yolov3_pytorch\n",
        "!ln -sf YOLOv3-PyTorch/tools tools\n",
        "!ln -sf YOLOv3-PyTorch/configs configs\n",
        "!ln -sf YOLOv3-PyTorch/model_configs model_configs"
      ],
      "metadata": {
        "id": "vvC8M70DzHPa"
      },
      "id": "vvC8M70DzHPa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patching source codes\n",
        "!mv tools/export.py tools/export.py.org\n",
        "!mv yolov3_pytorch/engine/trainer.py yolov3_pytorch/engine/trainer.py.org\n",
        "!wget http://www.agentspace.org/download/yolov3_pytorch_patch.zip\n",
        "!unzip -o yolov3_pytorch_patch.zip\n",
        "!rm yolov3_pytorch_patch.zip"
      ],
      "metadata": {
        "id": "RSPm6ypQ3xpT"
      },
      "id": "RSPm6ypQ3xpT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "id": "0XguG3gi2Giu"
      },
      "id": "0XguG3gi2Giu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take images, e.g. using https://imageonline.io/take-photo/"
      ],
      "metadata": {
        "id": "WRhr2LP5hq8O"
      },
      "id": "WRhr2LP5hq8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotate images, using https://www.makesense.ai/ add label / select ROI + label / action / export / yolo"
      ],
      "metadata": {
        "id": "5RCNatkJhuFK"
      },
      "id": "5RCNatkJhuFK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download train and test images with annotations\n",
        "!wget http://www.agentspace.org/download/watch-annotated.zip\n",
        "!unzip -o watch-annotated.zip\n",
        "!rm watch-annotated.zip"
      ],
      "metadata": {
        "id": "hVDCnmWYhmjp"
      },
      "id": "hVDCnmWYhmjp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!more data/custom/labels/train/000010.txt"
      ],
      "metadata": {
        "id": "9pBKk5EazlTe"
      },
      "id": "9pBKk5EazlTe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show train images\n",
        "\n",
        "def load(list_file):\n",
        "    samples = []\n",
        "    with open(list_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            img_path = line.strip()\n",
        "            if not img_path:\n",
        "                continue\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            annotation_path = img_path.replace(\".jpg\", \".txt\").replace('images', 'labels')\n",
        "            boxes = []\n",
        "            with open(annotation_path, \"r\") as g:\n",
        "                for record in g:\n",
        "                    box = [float(x) for x in record[:-1].split()]\n",
        "                    boxes.append(box)\n",
        "            samples.append((img,boxes))\n",
        "    return samples\n",
        "\n",
        "def show(samples):\n",
        "    plt.figure(figsize=(20, 4*(len(samples)+3)//4))\n",
        "    for i, (image,boxes) in enumerate(samples):\n",
        "        disp = np.copy(image)\n",
        "        H, W = disp.shape[:2]\n",
        "        for label, cx, cy, cw, ch in boxes:\n",
        "            x, y, w, h = (cx - cw/2)*W, (cy - ch/2)*H, cw*W, ch*H\n",
        "            cv2.rectangle(disp, (int(x), int(y)), (int(x+w), int(y+h)), (0, 255, 0), 2)\n",
        "            cv2.putText(disp, str(int(label)), (int(x)+3, int(y)+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        plt.subplot((len(samples)+3)//4, 4, i+1)\n",
        "        plt.imshow(cv2.cvtColor(disp,cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ma2Eo2BxNj5H"
      },
      "id": "Ma2Eo2BxNj5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = load(\"data/custom/train.txt\")\n",
        "show(train_samples)"
      ],
      "metadata": {
        "id": "Uwt44QI5VSDY"
      },
      "id": "Uwt44QI5VSDY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = load(\"data/custom/test.txt\")\n",
        "show(test_samples)"
      ],
      "metadata": {
        "id": "nxMBavOnVThw"
      },
      "id": "nxMBavOnVThw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lR model_configs/"
      ],
      "metadata": {
        "id": "3oB436lDEQtU"
      },
      "id": "3oB436lDEQtU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -v model_configs/COCO-Detection/yolov3_tiny.cfg yolov3_tiny.cfg"
      ],
      "metadata": {
        "id": "F48RpkHY3Ayn"
      },
      "id": "F48RpkHY3Ayn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edit yolov3_tiny.cfg and set the class number to 1\n",
        "# change classes in each YOLO layer\n",
        "# change filters to (5 + classes) * num_masked_anchors in the convolutional layer before the YOLO layer\n",
        "# (e.g. we have 6 anchors with mask 0,1,2 i.e. we have used 3 anchors)\n",
        "# (6*3=18)\n",
        "!sed -i -e 's/^\\s*filters\\s*=\\s*255/filters=18/' -e 's/^\\s*classes\\s*=\\s*80/classes=1/' yolov3_tiny.cfg"
      ],
      "metadata": {
        "id": "wYUW-bzf3Mt-"
      },
      "id": "wYUW-bzf3Mt-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download pretrained model\n",
        "!wget -O YOLOv3_Tiny-VOC-20231107.pth.tar http://agentspace.org/download/YOLOv3_Tiny-VOC-20231107.pth.tar"
      ],
      "metadata": {
        "id": "t-c_gFblvqJj"
      },
      "id": "t-c_gFblvqJj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l YOLOv3_Tiny-VOC-20231107.pth.tar"
      ],
      "metadata": {
        "id": "_smnnq5TpYIU"
      },
      "id": "_smnnq5TpYIU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lR configs/"
      ],
      "metadata": {
        "id": "3_VOHAO4-1In"
      },
      "id": "3_VOHAO4-1In",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -v configs/COCO-Detection/yolov3.yaml yolov3_tiny.yaml"
      ],
      "metadata": {
        "id": "ZK2EMoK9-9vL"
      },
      "id": "ZK2EMoK9-9vL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edit yolov3_tiny.yaml\n",
        "# change mainly CONFIG_PATH, NUM_CLASSES, CLASS_NAMES, dataset ROOT and pretrained model WEIGHTS_PATH\n",
        "\n",
        "import yaml\n",
        "# Load YAML\n",
        "with open(\"yolov3_tiny.yaml\", \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "# Modify fields\n",
        "cfg[\"PROJECT_NAME\"] = \"watch_detector_yolov3_tiny\"\n",
        "cfg[\"EXP_NAME\"] = \"watch_detector_yolov3_tiny\"\n",
        "cfg[\"MODEL\"][\"CONFIG_PATH\"] = \"./yolov3_tiny.cfg\"\n",
        "cfg[\"MODEL\"][\"NUM_CLASSES\"] = 1\n",
        "cfg[\"MODEL\"][\"IMG_SIZE\"] = 416 #512\n",
        "cfg[\"CLASS_NAMES\"] = [\"watch\"]\n",
        "cfg[\"TRAIN\"][\"DATASET\"][\"ROOT\"] = \"./data/custom/train.txt\"\n",
        "cfg[\"TRAIN\"][\"DATASET\"][\"CACHE\"] = True\n",
        "cfg[\"TRAIN\"][\"WEIGHTS_PATH\"] = \"./YOLOv3_Tiny-VOC-20231107.pth.tar\"\n",
        "cfg[\"TRAIN\"][\"HYP\"][\"EPOCHS\"] = 20000\n",
        "cfg[\"TRAIN\"][\"HYP\"][\"IMG_PER_BATCH\"] = 5\n",
        "cfg[\"TRAIN\"][\"HYP\"][\"ACCUMULATE_BATCH_SIZE\"] = 2\n",
        "cfg[\"TRAIN\"][\"SAVE_EVERY_EPOCH\"] = 100\n",
        "cfg[\"VAL\"][\"DATASET\"][\"ROOT\"] = \"./data/custom/test.txt\"\n",
        "cfg[\"VAL\"][\"DATASET\"][\"CACHE\"] = True\n",
        "\n",
        "# Save YAML\n",
        "with open(\"yolov3_tiny.yaml\", \"w\") as f:\n",
        "    yaml.safe_dump(cfg, f, sort_keys=False)"
      ],
      "metadata": {
        "id": "huJJGS8x_Gdc"
      },
      "id": "huJJGS8x_Gdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rfd results/train"
      ],
      "metadata": {
        "id": "Xw_vGuLxrK8Z"
      },
      "id": "Xw_vGuLxrK8Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "import sys\n",
        "sys.argv = [ 'train.py', './yolov3_tiny.yaml' ]\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "from tools.train import main as train\n",
        "train()"
      ],
      "metadata": {
        "id": "2PBeDO120DTn"
      },
      "id": "2PBeDO120DTn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download checkpoint after 20000 iterations instead of training\n",
        "#!mkdir -p results/train/watch_detector_yolov3_tiny\n",
        "#!rm -f results/train/watch_detector_yolov3_tiny/last.pth.tar\n",
        "#!wget -O results/train/watch_detector_yolov3_tiny/last.pth.tar http://agentspace.org/download/watch_checkpoint_020000.pth.tar"
      ],
      "metadata": {
        "id": "Fpn4MAxV5gQ0"
      },
      "id": "Fpn4MAxV5gQ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lR results/train"
      ],
      "metadata": {
        "id": "J2p1uujUUf_5"
      },
      "id": "J2p1uujUUf_5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the newest last.pth.tar and copy it into the result model\n",
        "import glob\n",
        "import os\n",
        "files = glob.glob(\"./results/train/watch_detector_yolov3_tiny*/last.pth.tar\")\n",
        "if not files:\n",
        "    print(\"No last.pth.tar files found\")\n",
        "else:\n",
        "    newest = max(files, key=os.path.getmtime)\n",
        "    print(\"found\", newest)"
      ],
      "metadata": {
        "id": "vUgx4_GB7hD5"
      },
      "id": "vUgx4_GB7hD5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 yolov3_tiny.cfg"
      ],
      "metadata": {
        "id": "lMowc2FpyObw"
      },
      "id": "lMowc2FpyObw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change batch size\n",
        "!sed -i 's/#batch = 1/batch=1/' yolov3_tiny.cfg\n",
        "!sed -i 's/#subdivisions = 1/subdivisions = 1/' yolov3_tiny.cfg\n",
        "!sed -i 's/batch = 64/#batch = 64/' yolov3_tiny.cfg\n",
        "!sed -i 's/subdivisions = 8/#subdivisions = 8/' yolov3_tiny.cfg"
      ],
      "metadata": {
        "id": "i4My44uloz9i"
      },
      "id": "i4My44uloz9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 yolov3_tiny.cfg"
      ],
      "metadata": {
        "id": "_2tcH7FAyIzj"
      },
      "id": "_2tcH7FAyIzj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export model\n",
        "import sys\n",
        "sys.argv = [\n",
        "    'export.py',\n",
        "    '--img-size', '416',\n",
        "    '--cfg', './yolov3_tiny.cfg',\n",
        "    '--weights', newest,\n",
        "    '--export-mode', 'torch',\n",
        "    '--export-dir', './results/export'\n",
        "]\n",
        "from tools.export import main as export\n",
        "export()\n"
      ],
      "metadata": {
        "id": "D-gbnMdu9KoG"
      },
      "id": "D-gbnMdu9KoG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l results/export"
      ],
      "metadata": {
        "id": "Qss9J_MDEmPT"
      },
      "id": "Qss9J_MDEmPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv -fv results/export/last.pth watch_detector_yolov3_tiny.pth\n",
        "!ls -l watch_detector_yolov3_tiny.pth"
      ],
      "metadata": {
        "id": "U9z16eed_yDP"
      },
      "id": "U9z16eed_yDP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('watch_detector_yolov3_tiny.pth')"
      ],
      "metadata": {
        "id": "APPscS5d6S8j"
      },
      "id": "APPscS5d6S8j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download trained and exported model (instead of the training and export)\n",
        "#!rm -f watch_detector_yolov3_tiny.pth\n",
        "#!wget http://www.agentspace.org/download/watch_detector_yolov3_tiny.pth"
      ],
      "metadata": {
        "id": "Lytl42tFdPdC"
      },
      "id": "Lytl42tFdPdC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "import yolov3_pytorch\n",
        "from yolov3_pytorch.utils import scale_coords, xyxy2xywh, non_max_suppression, plot_one_box\n",
        "from yolov3_pytorch.data.data_augment import letterbox\n",
        "model_path = 'watch_detector_yolov3_tiny.pth'\n",
        "model = torch.load(model_path, weights_only=False).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "jpPbdfa4dWrz"
      },
      "id": "jpPbdfa4dWrz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['watch']"
      ],
      "metadata": {
        "id": "WJUeqsKhds_i"
      },
      "id": "WJUeqsKhds_i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load image\n",
        "frame = cv2.imread(\"data/custom/images/test/000011.jpg\")\n",
        "frame.shape"
      ],
      "metadata": {
        "id": "LVG_U1SId0Fq"
      },
      "id": "LVG_U1SId0Fq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "img_size = 416\n",
        "img, _, _ = letterbox(frame,new_shape=img_size)\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "blob = cv2.dnn.blobFromImage(img,1.0/255)\n",
        "blob = torch.tensor(blob)\n",
        "blob = blob.to(device)\n",
        "blob.shape"
      ],
      "metadata": {
        "id": "3P4O45FLC86T"
      },
      "id": "3P4O45FLC86T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "with torch.no_grad():\n",
        "    output, _ = model(blob, False)\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "id": "fQAh_yzsDFRl"
      },
      "id": "fQAh_yzsDFRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# postprocessing - non-maximum supression\n",
        "conf_thresh = 0.08\n",
        "iou_thresh = 0.45\n",
        "detections = non_max_suppression(output, conf_thresh, iou_thresh)[0]\n",
        "detections.shape"
      ],
      "metadata": {
        "id": "PcQ2oyfzDJ66"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PcQ2oyfzDJ66"
    },
    {
      "cell_type": "code",
      "source": [
        "# postprocessing - rescaling\n",
        "detections[:, :4] = scale_coords(blob.shape[2:], detections[:, :4], frame.shape).round()"
      ],
      "metadata": {
        "id": "EjMtWxQrBXUk"
      },
      "id": "EjMtWxQrBXUk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize result\n",
        "disp = np.copy(frame)\n",
        "for detection in detections:\n",
        "    *xyxy, confidence, classid  = detection\n",
        "    plot_one_box(xyxy, disp, label=names[classid.int().item()], color=(0,0,255))\n",
        "\n",
        "plt.imshow(cv2.cvtColor(disp,cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGxTAgA7eNur"
      },
      "id": "EGxTAgA7eNur",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process image (all in one)\n",
        "def process_image(frame, conf_thresh=0.1, iou_thresh=0.45):\n",
        "    img_size = 416\n",
        "    img, _, _ = letterbox(frame,new_shape=img_size)\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    blob = cv2.dnn.blobFromImage(img,1.0/255)\n",
        "    blob = torch.tensor(blob)\n",
        "    blob = blob.to(device)\n",
        "    with torch.no_grad():\n",
        "        output, _ = model(blob, False)\n",
        "    detections = non_max_suppression(output, conf_thresh, iou_thresh)[0]\n",
        "    if detections is None:\n",
        "        return frame\n",
        "    detections[:, :4] = scale_coords(blob.shape[2:], detections[:, :4], frame.shape).round()\n",
        "    disp = np.copy(frame)\n",
        "    for detection in detections:\n",
        "        *xyxy, confidence, classid  = detection\n",
        "        plot_one_box(xyxy, disp, label=names[classid.int().item()], color=(0,0,255))\n",
        "    return disp"
      ],
      "metadata": {
        "id": "2Z9vL2b-d59A"
      },
      "id": "2Z9vL2b-d59A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload video\n",
        "#!wget http://www.agentspace.org/download/watch.avi\n",
        "#videofile = 'watch.avi'"
      ],
      "metadata": {
        "id": "JHTXPyyiGSj-"
      },
      "id": "JHTXPyyiGSj-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload video\n",
        "from google.colab import files\n",
        "print('upload video')\n",
        "uploaded = files.upload()\n",
        "videofile = list(uploaded.keys())[0]\n",
        "print(videofile)"
      ],
      "metadata": {
        "id": "ToaXT_FfgIBw"
      },
      "id": "ToaXT_FfgIBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process video\n",
        "resultfile = 'result.avi'\n",
        "video = cv2.VideoCapture(videofile)\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "hasFrame, frame = video.read()\n",
        "out = cv2.VideoWriter()\n",
        "out.open(resultfile,cv2.VideoWriter_fourcc('M','J','P','G'),fps,(frame.shape[1],frame.shape[0]))\n",
        "while True:\n",
        "    result = process_image(frame, conf_thresh=0.08, iou_thresh=0.45)\n",
        "    out.write(result)\n",
        "    hasFrame, frame = video.read()\n",
        "    if not hasFrame:\n",
        "        break\n",
        "out.release()"
      ],
      "metadata": {
        "id": "u8stOPZbgNaT"
      },
      "id": "u8stOPZbgNaT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download video\n",
        "files.download(resultfile)"
      ],
      "metadata": {
        "id": "mTcdCxIbgQrT"
      },
      "id": "mTcdCxIbgQrT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}