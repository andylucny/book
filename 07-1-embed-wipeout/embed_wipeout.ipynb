{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "eAxNySR7uqEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # konverzia na tensor [0,1]\n",
        "    #transforms.Normalize((0.5,), (0.5,))  # normalizÃ¡cia\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Pf-AHRkOuv9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_loader))\n",
        "print(sample[0].shape,sample[0].min(),sample[0].max())"
      ],
      "metadata": {
        "id": "4IuYkkW6u4kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.scale = nn.Parameter(torch.ones(dim))  # learnable scale per feature\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch, embed_dim]\n",
        "        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
        "        return (x / rms) * self.scale  # elementwise scale"
      ],
      "metadata": {
        "id": "j6KNvS_dvOyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_dim=28*28, embed_dim=384, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(in_dim, embed_dim)   # patch embedding\n",
        "        self.norm = RMSNorm(embed_dim)                  # RMS normalization\n",
        "        self.wipeout = nn.Linear(embed_dim, num_classes, bias=False)  # wipeout\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch, 1, 28, 28]\n",
        "        x = x.view(x.size(0), -1)        # sploÅ¡tÃ­ obraz: [batch, 784]\n",
        "        x = self.embedding(x)            # [batch, 384]\n",
        "        x = self.norm(x)                 # RMS norm\n",
        "        return self.wipeout(x)           # [batch, 10]"
      ],
      "metadata": {
        "id": "9sktSCZRvYjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "3MUYUyn5vdIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)"
      ],
      "metadata": {
        "id": "S5s6-OuhvfKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ§© Trainable parameters by layer:\")\n",
        "total_params = 0\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        num_params = param.numel()\n",
        "        print(f\"{name:25s} : {num_params:,}\")\n",
        "        total_params += num_params\n",
        "\n",
        "print(f\"\\nðŸ”¢ Total trainable parameters: {total_params:,}\\n\")"
      ],
      "metadata": {
        "id": "mQVjHkCnxZhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "_ZTIGNGGvoP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "epoch = 0\n",
        "\n",
        "def train(num_epochs):\n",
        "    global epoch\n",
        "    for _ in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "        epoch += 1"
      ],
      "metadata": {
        "id": "ea5FOF8BvxI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 400\n",
        "train(num_epochs)"
      ],
      "metadata": {
        "id": "xbsqp1nby9Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100)"
      ],
      "metadata": {
        "id": "htWyEZ6XHLJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model and weights\n",
        "classifier_name = 'mnist2vec.pth'\n",
        "\n",
        "def save():\n",
        "    torch.save(model.state_dict(), classifier_name) # weights only\n",
        "    print('Saved trained model at %s ' % classifier_name)\n",
        "\n",
        "save()"
      ],
      "metadata": {
        "id": "vTK1MNCg1NiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download model\n",
        "from google.colab import files\n",
        "files.download(classifier_name)"
      ],
      "metadata": {
        "id": "LxH0EYVJ1eW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of trainig, we can download its result\n",
        "#!wget http://agentspace.org/download/mnist2vec.pth\n",
        "#model.load_state_dict(torch.load(\"mnist2vec.pth\", map_location=torch.device(device)))"
      ],
      "metadata": {
        "id": "yF4B_iiuyMkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIt5Y4QVuoFb"
      },
      "outputs": [],
      "source": [
        "# evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get few samples\n",
        "test_iter = iter(test_loader)\n",
        "x_sample, _ = next(test_iter)\n",
        "print(x_sample.shape)"
      ],
      "metadata": {
        "id": "vNSUjM4Ez1OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the model on the samples\n",
        "input_images = x_sample[0:100].to(device)\n",
        "output_probabilities = model(input_images).to('cpu')\n",
        "output_categories = [ category.item() for category in torch.argmax(output_probabilities, dim=1) ]\n",
        "print(output_categories)"
      ],
      "metadata": {
        "id": "dX0wcFCFz2OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(output_categories)"
      ],
      "metadata": {
        "id": "FXOCGTrSGk7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show results\n",
        "def render(digit):\n",
        "    img = np.zeros((28, 28), dtype=np.uint8)\n",
        "    cv2.putText(img, str(digit), (6, 22), cv2.FONT_HERSHEY_SIMPLEX, 0.9, 255, 2)\n",
        "    return img\n",
        "\n",
        "plt.figure(figsize=(20, 40))\n",
        "for b in range(10):\n",
        "    for i in range(10):\n",
        "        input_img = (x_sample[10*b+i].squeeze(0).detach().numpy()*255).astype(np.uint8)\n",
        "        plt.subplot(20, 10, 20*b+i+1)\n",
        "        plt.imshow(input_img, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        output_img = render(output_categories[10*b+i])\n",
        "        plt.subplot(20, 10, 20*b+i+1+10)\n",
        "        plt.imshow(~output_img, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_gtzUB3tz8ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# back projection\n",
        "def backproject_to_image(model):\n",
        "    with torch.no_grad():\n",
        "        We = model.embedding.weight.detach().cpu()     # [384, 784]\n",
        "        Wb = model.embedding.bias.detach().cpu()       # [384]\n",
        "        Wc = model.wipeout.weight.detach().cpu()    # [10, 384]\n",
        "        scale = model.norm.scale.detach().cpu()        # [384]\n",
        "\n",
        "        # pseudo-inverse of embedding\n",
        "        We_pinv = torch.linalg.pinv(We)  # [784, 384]\n",
        "\n",
        "        imgs = []\n",
        "        for k in range(10):\n",
        "            proto = (Wc[k] / scale)  # inverse RMSNorm scaling\n",
        "            x_recon = We_pinv @ (proto-Wb)  # least squares inverse\n",
        "            img = x_recon.view(28, 28)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = torch.stack(imgs)\n",
        "    return imgs\n",
        "\n",
        "# Get 10 reconstructed \"digit prototypes\"\n",
        "proto_imgs = backproject_to_image(model)"
      ],
      "metadata": {
        "id": "OGlLGKgw5vQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proto_imgs.shape, proto_imgs.min(), proto_imgs.max()"
      ],
      "metadata": {
        "id": "RiYShGy06H31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show prototypes\n",
        "plt.figure(figsize=(20, 40))\n",
        "for i in range(10):\n",
        "    mn = proto_imgs[i].min()\n",
        "    mx = proto_imgs[i].max()\n",
        "    input_img = (((proto_imgs[i]-mn)/(mx-mn)).cpu().detach().numpy()*255).astype(np.uint8)\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(input_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ujswsDFV57bN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}