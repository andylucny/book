{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KRw84bb7vLrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), lambda x: (x > 0.5).float()])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "bVjTE2YLvRfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "SSfKFJ24vSkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# architecture\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(7*7*64, latent_dim * 2)  # Mean and log-variance\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 7*7*32), nn.ReLU(),\n",
        "            nn.Unflatten(1, (32, 7, 7)),\n",
        "            nn.ConvTranspose2d(32, 64, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ConvTranspose2d(32, 1, 3, stride=1, padding=1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mean, logvar = h[:, :self.latent_dim], h[:, self.latent_dim:]\n",
        "        return mean, logvar\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        std = torch.exp(0.5 * logvar) # == torch.sqrt(torch.exp(logvar))\n",
        "        eps = torch.randn_like(std)\n",
        "        return mean + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mean, logvar)\n",
        "        x_recon = self.decode(z)\n",
        "        return x_recon, mean, logvar"
      ],
      "metadata": {
        "id": "gmJGGGVFveER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "def loss_function(x_recon, x, mean, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(x_recon, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "tle0fWsDvfwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "latent_dim = 2\n",
        "model = CVAE(latent_dim).to('cuda')"
      ],
      "metadata": {
        "id": "Zcq9vVN5vqu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "MoKU9o6bv21n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 230\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        x, _ = batch\n",
        "        x = x.to('cuda')\n",
        "        optimizer.zero_grad()\n",
        "        x_recon, mean, logvar = model(x)\n",
        "        loss = loss_function(x_recon, x, mean, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {train_loss/len(train_loader.dataset)}')"
      ],
      "metadata": {
        "id": "-tTZWWP8v1Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model\n",
        "torch.save(model.state_dict(), 'mnist_cvae_encoder.pth')"
      ],
      "metadata": {
        "id": "_QIbNeDzwCjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the decoder\n",
        "torch.save(model.decoder,'mnist_cvae_decoder.pth')"
      ],
      "metadata": {
        "id": "8IpP18IjwXQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to use the decoder in pytorch\n",
        "dummy_input = torch.tensor([[0,0]],dtype=torch.float32).to('cuda')\n",
        "print(model.decoder(dummy_input).shape) # [1, 1, 28, 28]"
      ],
      "metadata": {
        "id": "2PxAI2lswVva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UlbH2BmvJPe"
      },
      "outputs": [],
      "source": [
        "# Plot latent space\n",
        "def plot_latent_space(model, n=20, figsize=15):\n",
        "    global grid_x, grid_y\n",
        "    norm = torch.distributions.Normal(0, 1)\n",
        "    grid_x = norm.icdf(torch.linspace(0.05, 0.95, n-1))\n",
        "    grid_y = norm.icdf(torch.linspace(0.05, 0.95, n-1))\n",
        "    figure = np.zeros((28 * (n-1), 28 * (n-1)))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, yi in enumerate(grid_x):\n",
        "            for j, xi in enumerate(grid_y):\n",
        "                z = torch.tensor([[xi, yi]]).float().to('cuda')\n",
        "                x_decoded = model.decode(z)\n",
        "                digit = x_decoded[0].reshape(28, 28).cpu().numpy()\n",
        "                figure[i * 28: (i + 1) * 28, j * 28: (j + 1) * 28] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    plt.imshow(figure, cmap='Greys_r')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('latent_space.png')\n",
        "\n",
        "plot_latent_space(model)"
      ]
    }
  ]
}