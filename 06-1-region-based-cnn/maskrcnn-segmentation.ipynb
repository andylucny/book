{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision opencv-python matplotlib"
      ],
      "metadata": {
        "id": "mCZtHU5E2R8T"
      },
      "id": "mCZtHU5E2R8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.agentspace.org/download/watch-masks.zip\n",
        "!unzip watch-masks.zip\n",
        "!rm watch-masks.zip"
      ],
      "metadata": {
        "id": "6zjG8jO58H1o"
      },
      "id": "6zjG8jO58H1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "from torchvision.transforms.v2 import Compose, ToTensor, ConvertImageDtype, Resize\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, cv2"
      ],
      "metadata": {
        "id": "J9xh3g9YGz9O"
      },
      "id": "J9xh3g9YGz9O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSegmentationDataset(Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = sorted(os.listdir(os.path.join(root, \"images\")))\n",
        "        self.masks = sorted(os.listdir(os.path.join(root, \"masks\")))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
        "\n",
        "        img = cv2.imread(img_path)[:, :, ::-1].copy()  # BGRâ†’RGB, add .copy() to fix negative stride issue\n",
        "        mask = cv2.imread(mask_path, 0)         # grayscale\n",
        "\n",
        "        # get unique object ids\n",
        "        obj_ids = np.unique(mask)\n",
        "        obj_ids = obj_ids[1:]  # remove background id 0\n",
        "\n",
        "        masks = mask == obj_ids[:, None, None]\n",
        "        num_objs = len(obj_ids)\n",
        "\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.where(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)  # all one class\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": image_id,\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "7Fe5wn7XHIke"
      },
      "id": "7Fe5wn7XHIke",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f984269"
      },
      "source": [
        "# Training\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for images, targets in train_loader:\n",
        "        images = list(img.cuda() for img in images)\n",
        "        targets = [{k: v.cuda() for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch [{epoch}], Step [{i}], Loss: {losses.item():.4f}\")\n",
        "        i += 1"
      ],
      "id": "0f984269",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_instance_segmentation_model(num_classes):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    # Replace the classifier head\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
        "        in_features, num_classes)\n",
        "\n",
        "    # Replace the mask head\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask, hidden_layer, num_classes)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "pgtMWnbqHP0V"
      },
      "id": "pgtMWnbqHP0V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "transforms = Compose([\n",
        "    ToTensor(),\n",
        "    ConvertImageDtype(torch.float32),\n",
        "    Resize((800,1333)),\n",
        "])\n",
        "\n",
        "dataset_train = CustomSegmentationDataset('watch/train', transforms=transforms)\n",
        "dataset_val = CustomSegmentationDataset('watch/val', transforms=transforms)\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=2, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(dataset_val, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "fuRchHO_HcSD"
      },
      "id": "fuRchHO_HcSD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "num_classes = 2  # background + 1 custom class\n",
        "model = get_instance_segmentation_model(num_classes)\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "A3VhNgyZHkIB"
      },
      "id": "A3VhNgyZHkIB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
      ],
      "metadata": {
        "id": "9zkmHiBmHuFV"
      },
      "id": "9zkmHiBmHuFV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for images, targets in train_loader:\n",
        "        images = list(img.cuda() for img in images)\n",
        "        targets = [{k: v.cuda() for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"Epoch [{epoch}], Step [{i}], Loss: {losses.item():.4f}\")\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "mFnZmtq0Hz8b"
      },
      "id": "mFnZmtq0Hz8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the trained model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    img = cv2.imread(\"dataset/val/images/img001.jpg\")[:, :, ::-1]\n",
        "    img_tensor = T.ToTensor()(img).cuda()\n",
        "    pred = model([img_tensor])[0]"
      ],
      "metadata": {
        "id": "ImiAnBSlIDwx"
      },
      "id": "ImiAnBSlIDwx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = pred[\"masks\"] > 0.5\n",
        "vis = draw_segmentation_masks(torch.from_numpy(img).permute(2,0,1), masks.squeeze(1), alpha=0.5)\n",
        "plt.imshow(vis.permute(1,2,0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yyy2ZcMQKHJJ"
      },
      "id": "yyy2ZcMQKHJJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}