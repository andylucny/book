{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import io\n",
        "import requests\n",
        "import zipfile\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "D5yFz-6HXVQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "6ZrOuE-NW_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_zipfile(path,url):\n",
        "    if os.path.exists(path):\n",
        "        return\n",
        "    print(\"downloading\",url)\n",
        "    response = requests.get(url)\n",
        "    if response.ok:\n",
        "        file_like_object = io.BytesIO(response.content)\n",
        "        zipfile_object = zipfile.ZipFile(file_like_object)\n",
        "        zipfile_object.extractall(\".\")\n",
        "    print(\"downloaded\")\n",
        "\n",
        "def download_glee():\n",
        "    download_zipfile('GLEEmodel_swin_complete.pth','http://www.agentspace.org/download/GLEEmodel_swin_complete.zip')\n",
        "\n",
        "download_glee()"
      ],
      "metadata": {
        "id": "Lh9E9Ujpqvun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('GLEEmodel_swin_complete.pth').to(device)"
      ],
      "metadata": {
        "id": "Rf2nHm1Zseyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O \"twocats.jpg\" \"http://images.cocodataset.org/val2017/000000039769.jpg\""
      ],
      "metadata": {
        "id": "3jJmAXh4oszO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgpath='twocats.jpg'"
      ],
      "metadata": {
        "id": "H9L0G-9hXgzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(imgpath)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "vXyx3TxskzxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_imshow(img)"
      ],
      "metadata": {
        "id": "Kw2Apxnys3G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "def LSJ_box_postprocess( out_bbox,  padding_size, crop_size, img_h, img_w): # postprocess box height and width\n",
        "    boxes = box_cxcywh_to_xyxy(out_bbox)\n",
        "    lsj_scale = torch.tensor([padding_size[1], padding_size[0], padding_size[1], padding_size[0]]).to(out_bbox)\n",
        "    crop_scale = torch.tensor([crop_size[1], crop_size[0], crop_size[1], crop_size[0]]).to(out_bbox)\n",
        "    boxes = boxes * lsj_scale\n",
        "    boxes = boxes / crop_scale\n",
        "    boxes = torch.clamp(boxes,0,1)\n",
        "    scale_fct = torch.tensor([img_w, img_h, img_w, img_h])\n",
        "    scale_fct = scale_fct.to(out_bbox)\n",
        "    boxes = boxes * scale_fct\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "mbpfAXN6sPdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_expressions = [ \"the first sleeping cat from the right side\" ]\n",
        "prompt_list = {'grounding':input_expressions}\n",
        "task=\"grounding\""
      ],
      "metadata": {
        "id": "cSvASPYps0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "copyed_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "print('input shape',copyed_img.shape)\n",
        "pixel_mean = torch.Tensor( [123.675, 116.28, 103.53]).to(device).view(3, 1, 1)\n",
        "pixel_std = torch.Tensor([58.395, 57.12, 57.375]).to(device).view(3, 1, 1)\n",
        "normalizer = lambda x: (x - pixel_mean) / pixel_std\n",
        "inference_size = 800\n",
        "resizer = torchvision.transforms.Resize(inference_size,antialias=True)\n",
        "size_divisibility = 32\n",
        "ori_image = torch.as_tensor(np.ascontiguousarray( copyed_img.transpose(2, 0, 1)))\n",
        "ori_image = normalizer(ori_image.to(device))[None,]\n",
        "_,_, ori_height, ori_width = ori_image.shape\n",
        "resize_image = resizer(ori_image)\n",
        "image_size = torch.as_tensor((resize_image.shape[-2],resize_image.shape[-1]))\n",
        "re_size = resize_image.shape[-2:]\n",
        "if size_divisibility > 1:\n",
        "    stride = size_divisibility\n",
        "    padding_size = ((image_size + (stride - 1)).div(stride, rounding_mode=\"floor\") * stride).tolist()\n",
        "    infer_image = torch.zeros(1,3,padding_size[0],padding_size[1]).to(resize_image)\n",
        "    infer_image[0,:,:image_size[0],:image_size[1]] = resize_image\n",
        "    infer_image = infer_image.to(device)"
      ],
      "metadata": {
        "id": "dYXEzySkttlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model into GPU\n",
        "t0 = time.time()\n",
        "dummy = torch.rand(infer_image.shape).to(device)\n",
        "with torch.no_grad():\n",
        "    (outputs,_) = model(dummy, prompt_list, task=task, batch_name_list=[], is_train=False)\n",
        "t1 = time.time()\n",
        "print(f'model loaded in {t1-t0}s')"
      ],
      "metadata": {
        "id": "qNvEPx61twbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_select=['box', 'mask', 'name', 'score', 'expression']"
      ],
      "metadata": {
        "id": "MxdfjE27t5-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run model\n",
        "t0 = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    (outputs,_) = model(infer_image, prompt_list, task=\"grounding\", batch_name_list=[], is_train=False)\n",
        "\n",
        "mask_pred = outputs['pred_masks'][0].to('cpu')\n",
        "mask_cls = outputs['pred_logits'][0].to('cpu')\n",
        "boxes_pred = outputs['pred_boxes'][0].to('cpu')\n",
        "\n",
        "t1 = time.time()\n",
        "print('elapsed',t1-t0,'s') # 2.96s s loadovanim modelu, 0.65s bez loadovania na CUDA, 7,86s CPU"
      ],
      "metadata": {
        "id": "CzBc2FEAuAKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# postprocessing\n",
        "scores = mask_cls.sigmoid().max(-1)[0]\n",
        "topK_instance = 1\n",
        "scores_per_image, topk_indices = scores.topk(topK_instance, sorted=True)\n",
        "\n",
        "pred_class = mask_cls[topk_indices].max(-1)[1].tolist()\n",
        "pred_boxes = boxes_pred[topk_indices]\n",
        "\n",
        "boxes = LSJ_box_postprocess(pred_boxes,padding_size,re_size, ori_height,ori_width)\n",
        "mask_pred = mask_pred[topk_indices]\n",
        "pred_masks = F.interpolate( mask_pred[None,], size=(padding_size[0], padding_size[1]), mode=\"bilinear\", align_corners=False  )\n",
        "pred_masks = pred_masks[:,:,:re_size[0],:re_size[1]]\n",
        "pred_masks = F.interpolate( pred_masks, size=(ori_height,ori_width), mode=\"bilinear\", align_corners=False  )\n",
        "pred_masks = (pred_masks>0).detach().cpu().numpy()[0]"
      ],
      "metadata": {
        "id": "Y-mDYwqTuP8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization\n",
        "COLORS = [\n",
        "    [0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "    [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933],\n",
        "    [0.494, 0.000, 0.556], [0.494, 0.000, 0.000], [0.000, 0.745, 0.000],\n",
        "    [0.700, 0.300, 0.600], [0.000, 0.447, 0.741], [0.850, 0.325, 0.098]\n",
        "]\n",
        "\n",
        "zero_mask = np.zeros_like(copyed_img)\n",
        "for nn, mask in enumerate(pred_masks):\n",
        "    mask = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
        "    lar = np.concatenate((mask*COLORS[nn%12][2], mask*COLORS[nn%12][1], mask*COLORS[nn%12][0]), axis = 2)\n",
        "    zero_mask = zero_mask+ lar\n",
        "\n",
        "lar_valid = zero_mask>0\n",
        "masked_image = lar_valid*copyed_img\n",
        "mask_image_mix_ration = 0.65\n",
        "img_n = masked_image*mask_image_mix_ration + np.clip(zero_mask,0,1)*255*(1-mask_image_mix_ration)\n",
        "max_p = img_n.max()\n",
        "img_n = 255*img_n/max_p\n",
        "ret = (~lar_valid*copyed_img)*mask_image_mix_ration + img_n\n",
        "ret = ret.astype('uint8')\n",
        "retimg = cv2.cvtColor(ret,cv2.COLOR_RGB2BGR)"
      ],
      "metadata": {
        "id": "qtJfzmURsG03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_imshow(retimg)"
      ],
      "metadata": {
        "id": "S-MknonzuhJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = pred_masks[0]\n",
        "mask = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
        "mask = mask.astype(np.uint8)\n",
        "mask = np.squeeze(mask)\n",
        "mask *= 255"
      ],
      "metadata": {
        "id": "sABOGOJuua4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_imshow(mask)"
      ],
      "metadata": {
        "id": "rSY4vb4qupvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}