{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629748fe",
      "metadata": {
        "id": "629748fe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840ebcbf",
      "metadata": {
        "id": "840ebcbf"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1b25843",
      "metadata": {
        "id": "b1b25843"
      },
      "outputs": [],
      "source": [
        "# dataloader for training\n",
        "train_loader = DataLoader(datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor()), batch_size=batch_size, shuffle=True)\n",
        "train_iter = iter(train_loader)\n",
        "# get first batch - images and labels\n",
        "x_sample, _ = next(train_iter)\n",
        "# float images 28 x 28, 0.0-1.0\n",
        "print(x_sample[0].shape,torch.max(x_sample[0]).item(),torch.min(x_sample[0]).item(),x_sample[0].dtype)\n",
        "# save first samples\n",
        "os.makedirs('mnist', exist_ok=True)\n",
        "for i in range(10):\n",
        "    cv2.imwrite('mnist/inp'+str(i).zfill(5)+\".png\",np.asarray(x_sample[i].squeeze(0).detach().numpy()*255,np.uint8))\n",
        "# show first samples\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(10):\n",
        "    img = (x_sample[i].squeeze(0).detach().numpy()*255).astype(np.uint8)\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43c8ef1",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "a43c8ef1"
      },
      "outputs": [],
      "source": [
        "# dataloader for testing\n",
        "test_loader = DataLoader(datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor()),batch_size=batch_size,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9e283ff",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f9e283ff"
      },
      "outputs": [],
      "source": [
        "# custom module\n",
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = tuple(map(int,args))\n",
        "    def forward(self, x):\n",
        "        return x.view((x.shape[0],)+self.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76dec433",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "76dec433"
      },
      "outputs": [],
      "source": [
        "# architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # convolution layers and max pooling of encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1,16,(3,3),padding=1),  # [n, 1, 28, 28] -> [n, 16, 28, 28] # 1 x 16 x (9 + 1)\n",
        "            nn.ReLU(),                        # -> # 0\n",
        "            nn.MaxPool2d(2),                  # [n, 16, 28, 28] -> [n, 16, 14, 14] # 0\n",
        "            nn.Conv2d(16,8,(3,3),padding=1),  # [n, 16, 14, 14] -> [n, 8, 14, 14] # 8 x (16 x 9 + 1)\n",
        "            nn.ReLU(),                        # -> # 0\n",
        "            nn.MaxPool2d(2),                  # [n, 8, 14, 14] -> [n, 8, 7, 7] # 0\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 7, 7] -> [n, 8, 7, 7]  # 8 x (8 * 9 + 1)\n",
        "            nn.Sigmoid(),                     # -> # 0\n",
        "            nn.MaxPool2d(2,padding=1),        # [n, 8, 7, 7] -> [n, 8, 4, 4] # 0\n",
        "            torch.nn.Flatten()                # [n, 8, 4, 4] -> [n, 128] # 0\n",
        "        )\n",
        "\n",
        "        # convolution layers and upsampling of decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            Reshape(8,4,4),                   # -> [n, 8, 4, 4] # 0\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 4, 4] -> [n, 8, 4, 4] # 8 x (8 * 9 + 1)\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),  # [n, 8, 4, 4] -> [n, 8, 8, 8] # 0\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 8, 8] -> [n, 8, 8, 8] # 8 x (8 * 9 + 1)\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),  # [n, 8, 8, 8] -> [n, 8, 16, 16]\n",
        "            nn.Conv2d(8,16,(3,3)),            # [n, 8, 16, 16] -> [n, 16, 14, 14] # 16 x (8 * 9 + 1)\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),  # [n, 16, 14, 14] -> [n, 16, 28, 28] # 0\n",
        "            nn.Conv2d(16,1,(3,3),padding=1),  # [n, 16, 28, 28] -> [n, 1, 28, 28] # 1 x (16 * 9 + 1)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # apply encoder\n",
        "        features = self.encoder(x)\n",
        "        # apply decoder\n",
        "        return self.decoder(features)\n",
        "    def __str__(self):\n",
        "        return str(self.encoder)+str(self.decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa2ea1f",
      "metadata": {
        "id": "4aa2ea1f"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder().to(device)\n",
        "print(autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6457d7",
      "metadata": {
        "id": "3f6457d7"
      },
      "outputs": [],
      "source": [
        "# Define optimizer\n",
        "optimizer = optim.Adadelta(autoencoder.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c03f9a",
      "metadata": {
        "id": "a7c03f9a"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "epochs_count = 60\n",
        "for epoch in range(epochs_count):\n",
        "\n",
        "    # change model in training mode\n",
        "    autoencoder.train()\n",
        "\n",
        "    # to record loss and accuracy\n",
        "    batch_loss = np.array([])\n",
        "    batch_acc = np.array([])\n",
        "\n",
        "    for batch, (x_train, _) in enumerate(train_loader):\n",
        "\n",
        "        # send data to device\n",
        "        input = x_train.to(device)\n",
        "\n",
        "        # reset parameters gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass to the model\n",
        "        output = autoencoder(input)\n",
        "\n",
        "        # cross entropy loss\n",
        "        loss = F.binary_cross_entropy(output, input)\n",
        "\n",
        "        # find gradients\n",
        "        loss.backward()\n",
        "        # update parameters using gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # recording loss\n",
        "        batch_loss = np.append(batch_loss, [loss.item()])\n",
        "\n",
        "        # recording accuracy\n",
        "        total_train = input.numel()\n",
        "        correct_train = (torch.abs(input-output) < 0.1).sum().item()\n",
        "        acc = (100.0 * correct_train) / total_train\n",
        "        batch_acc = np.append(batch_acc, [acc])\n",
        "\n",
        "        if batch % 100 == 0 and batch > 0:\n",
        "            print('Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(epoch, batch * len(input), len(train_loader.dataset), loss.item(), acc))\n",
        "\n",
        "    epoch_loss = batch_loss.mean()\n",
        "    epoch_acc = batch_acc.mean()\n",
        "\n",
        "    print('Epoch: {} Loss: {:.6f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3599dd",
      "metadata": {
        "id": "ce3599dd"
      },
      "outputs": [],
      "source": [
        "# validation (evaluation)\n",
        "total_test = 0\n",
        "correct_test = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bff22f",
      "metadata": {
        "id": "93bff22f"
      },
      "outputs": [],
      "source": [
        "for batch, (x_test, _) in enumerate(test_loader):\n",
        "\n",
        "    # send data to device\n",
        "    input = x_test.to(device)\n",
        "    input.to(device)\n",
        "\n",
        "    # forward pass to the model\n",
        "    output = autoencoder(input)\n",
        "\n",
        "    total_test += input.numel()\n",
        "    correct_test += (torch.abs(input-output) < 0.1).sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ced26af6",
      "metadata": {
        "id": "ced26af6"
      },
      "outputs": [],
      "source": [
        "test_acc = (100.0 * correct_test) / total_test\n",
        "print('Test accuracy: {:.4f}'.format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d48f9c",
      "metadata": {
        "id": "91d48f9c"
      },
      "outputs": [],
      "source": [
        "# save model weights\n",
        "model_name = 'pytorch_mnist_autoencoder_model.pth'\n",
        "torch.save(autoencoder.state_dict(), model_name) # weights only\n",
        "print(f'Saved trained model at {model_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77623ea",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "e77623ea"
      },
      "outputs": [],
      "source": [
        "# use the model on few samples\n",
        "input_images = x_sample[0:10].to(device)\n",
        "output_images = autoencoder(input_images).to('cpu')\n",
        "# save first results\n",
        "for i in range(10):\n",
        "    cv2.imwrite('mnist/out'+str(i).zfill(5)+\".png\",np.asarray(output_images[i].squeeze(0).detach().numpy()*255,np.uint8))\n",
        "# show first results\n",
        "plt.figure(figsize=(20, 7))\n",
        "for i in range(10):\n",
        "    input_img = (x_sample[i].squeeze(0).detach().numpy()*255).astype(np.uint8)\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(input_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    output_img = (output_images[i].squeeze(0).detach().numpy()*255).astype(np.uint8)\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(output_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "files.download(model_name)\n",
        "shutil.make_archive('mnist_results', 'zip', './mnist')\n",
        "files.download('mnist_results.zip')"
      ],
      "metadata": {
        "id": "Wa5hxTaMi18q"
      },
      "id": "Wa5hxTaMi18q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}