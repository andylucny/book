{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629748fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ebcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b25843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataloader\n",
    "train_loader = DataLoader(datasets.MNIST(root='data', train=True, download=True, transform=transforms.ToTensor()), batch_size=batch_size, shuffle=True)\n",
    "train_iter = iter(train_loader)\n",
    "# get first batch - images and labels\n",
    "x_sample, _ = next(train_iter)\n",
    "# float images 28 x 28, 0.0-1.0\n",
    "print(x_sample[0].shape,torch.max(x_sample[0]).item(),torch.min(x_sample[0]).item(),x_sample[0].dtype)\n",
    "# save first samples\n",
    "for i in range(10):\n",
    "    cv2.imwrite('mnist/inp'+str(i).zfill(5)+\".png\",np.asarray(x_sample[i].squeeze(0).detach().numpy()*255,np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c8ef1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# test dataloader\n",
    "test_loader = DataLoader(datasets.MNIST(root='data', train=False, download=True, transform=transforms.ToTensor()),batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e283ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# custom module\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = tuple(map(int,args))\n",
    "    def forward(self, x):\n",
    "        return x.view((x.shape[0],)+self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dec433",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # convolution layers and max pooling of encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,16,(3,3),padding=1),  # [n, 1, 28, 28] -> [n, 16, 28, 28] # 1 x 16 x (9 + 1)\n",
    "            nn.ReLU(),                        # -> # 0\n",
    "            nn.MaxPool2d(2),                  # [n, 16, 28, 28] -> [n, 16, 14, 14] # 0\n",
    "            nn.Conv2d(16,8,(3,3),padding=1),  # [n, 16, 14, 14] -> [n, 8, 14, 14] # 8 x (16 x 9 + 1)\n",
    "            nn.ReLU(),                        # -> # 0\n",
    "            nn.MaxPool2d(2),                  # [n, 8, 14, 14] -> [n, 8, 7, 7] # 0\n",
    "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 7, 7] -> [n, 8, 7, 7]  # 8 x (8 * 9 + 1)\n",
    "            nn.Sigmoid(),                     # -> # 0\n",
    "            nn.MaxPool2d(2,padding=1),        # [n, 8, 7, 7] -> [n, 8, 4, 4] # 0\n",
    "            torch.nn.Flatten()                # [n, 8, 4, 4] -> [n, 128] # 0\n",
    "        )\n",
    "        \n",
    "        # convolution layers and upsampling of decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            Reshape(8,4,4),                   # -> [n, 8, 4, 4] # 0\n",
    "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 4, 4] -> [n, 8, 4, 4] # 8 x (8 * 9 + 1)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=(2,2)),  # [n, 8, 4, 4] -> [n, 8, 8, 8] # 0\n",
    "            nn.Conv2d(8,8,(3,3),padding=1),   # [n, 8, 8, 8] -> [n, 8, 8, 8] # 8 x (8 * 9 + 1)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=(2,2)),  # [n, 8, 8, 8] -> [n, 8, 16, 16]\n",
    "            nn.Conv2d(8,16,(3,3)),            # [n, 8, 16, 16] -> [n, 16, 14, 14] # 16 x (8 * 9 + 1)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=(2,2)),  # [n, 16, 14, 14] -> [n, 16, 28, 28] # 0\n",
    "            nn.Conv2d(16,1,(3,3),padding=1),  # [n, 16, 28, 28] -> [n, 1, 28, 28] # 1 x (16 * 9 + 1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # apply encoder\n",
    "        features = self.encoder(x)\n",
    "        # apply decoder\n",
    "        return self.decoder(features)\n",
    "    def __str__(self):\n",
    "        return str(self.encoder)+str(self.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder().to(device)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6457d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.Adadelta(autoencoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c03f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "epochs_count = 100\n",
    "for epoch in range(epochs_count):\n",
    "\n",
    "    # change model in training mode\n",
    "    autoencoder.train()\n",
    "\n",
    "    # to record loss and accuracy\n",
    "    batch_loss = np.array([])\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch, (x_train, _) in enumerate(train_loader):\n",
    "        \n",
    "        # send data to device \n",
    "        input = x_train.to(device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = autoencoder(input)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.binary_cross_entropy(output, input)\n",
    "        \n",
    "        # find gradients \n",
    "        loss.backward()\n",
    "        # update parameters using gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # recording loss\n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # recording accuracy\n",
    "        total_train = input.numel()\n",
    "        correct_train = (torch.abs(input-output) < 0.1).sum().item()\n",
    "        acc = (100.0 * correct_train) / total_train\n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch % 100 == 0 and batch > 0:              \n",
    "            print('Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(epoch, batch * len(input), len(train_loader.dataset), loss.item(), acc))\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "\n",
    "    print('Epoch: {} Loss: {:.6f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3599dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation (evaluation)\n",
    "total_test = 0\n",
    "correct_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bff22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (x_test, _) in enumerate(test_loader):\n",
    "\n",
    "    # send data to device \n",
    "    input = x_test.to(device)\n",
    "    input.to(device)    \n",
    "\n",
    "    # forward pass to the model\n",
    "    output = autoencoder(input)\n",
    "    \n",
    "    total_test += input.numel()\n",
    "    correct_test += (torch.abs(input-output) < 0.1).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced26af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (100.0 * correct_test) / total_test\n",
    "print('Test accuracy: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d48f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "model_name = 'pytorch_mnist_autoencoder_model.pth'\n",
    "torch.save(autoencoder.state_dict(), model_name) # weights only\n",
    "print('Saved trained model at %s ' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77623ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# use the model on few samples\n",
    "input_images = x_sample[0:10].to(device)\n",
    "output_images = autoencoder(input_images).to('cpu')\n",
    "for i in range(10):\n",
    "    cv2.imwrite('mnist/out'+str(i).zfill(5)+\".png\",np.asarray(output_images[i].squeeze(0).detach().numpy()*255,np.uint8))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
