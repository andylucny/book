{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a4e1c5",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "37a4e1c5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, IntSlider\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab18a69",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5ab18a69"
      },
      "outputs": [],
      "source": [
        "# architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # convolution layers and max pooling of encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1,16,(3,3),padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16,8,(3,3),padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),\n",
        "            nn.Sigmoid(),\n",
        "            nn.MaxPool2d(2,padding=1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        # convolution layers and upsampling of decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Unflatten(1,(8,4,4)),\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),\n",
        "            nn.Conv2d(8,8,(3,3),padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),\n",
        "            nn.Conv2d(8,16,(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=(2,2)),\n",
        "            nn.Conv2d(16,1,(3,3),padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        # apply encoder\n",
        "        features = self.encoder(x)\n",
        "        # apply decoder\n",
        "        return self.decoder(features)\n",
        "    def __str__(self):\n",
        "        return str(self.encoder)+str(self.decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d4e3e8",
      "metadata": {
        "id": "d0d4e3e8"
      },
      "outputs": [],
      "source": [
        "autoencoder = Autoencoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc9810c",
      "metadata": {
        "id": "5cc9810c"
      },
      "outputs": [],
      "source": [
        "model_name = 'pytorch_mnist_autoencoder_model.pth'\n",
        "from google.colab import files\n",
        "print('upload',model_name)\n",
        "files.upload()\n",
        "autoencoder.load_state_dict(torch.load(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0170879",
      "metadata": {
        "id": "d0170879"
      },
      "outputs": [],
      "source": [
        "decoder = autoencoder.decoder\n",
        "decoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('upload inp00009.png')\n",
        "_ = files.upload()"
      ],
      "metadata": {
        "id": "iD_FJI8qOLs9"
      },
      "id": "iD_FJI8qOLs9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be65dd1",
      "metadata": {
        "id": "4be65dd1"
      },
      "outputs": [],
      "source": [
        "sample_image = cv2.imread('inp00009.png',cv2.IMREAD_GRAYSCALE)\n",
        "sample_blob = cv2.dnn.blobFromImage(sample_image,1.0/255.0)\n",
        "sample_features = autoencoder.encoder(torch.tensor(sample_blob))\n",
        "features = sample_features.squeeze(0).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_features.shape)"
      ],
      "metadata": {
        "id": "h2bNn0mWQ7vE"
      },
      "id": "h2bNn0mWQ7vE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d5911f",
      "metadata": {
        "id": "46d5911f"
      },
      "outputs": [],
      "source": [
        "# Keep a copy of features for updating\n",
        "features = sample_features[0].clone().detach()\n",
        "last_index = -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to update and display the generated image\n",
        "def update_latent(index=0, value=64):\n",
        "    global features, last_index\n",
        "    if last_index != index:\n",
        "        last_index = index\n",
        "        value_slider.value = int(features[index].item()*127)\n",
        "    else:\n",
        "        features[index] = value/127.0\n",
        "    features = features\n",
        "    with torch.no_grad():\n",
        "        coded = features.unsqueeze(0).unsqueeze(0)\n",
        "        decoded = decoder(coded).detach().squeeze(0).squeeze(0)\n",
        "    decoded = (decoded.numpy()*255).astype(np.uint8)\n",
        "    decoded_resized = cv2.resize(decoded, (420, 420), interpolation=cv2.INTER_NEAREST)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(decoded_resized, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2SWWSeJcPZfg"
      },
      "id": "2SWWSeJcPZfg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive sliders for latent space\n",
        "latent_dim = features.shape[0]\n",
        "index_slider = IntSlider(min=0, max=latent_dim-1, step=1, value=0, description='Index')\n",
        "value_slider = IntSlider(min=0, max=127, step=1, value=int(features[0].item()*127), description='Value')"
      ],
      "metadata": {
        "id": "7MY2z-L7PXPE"
      },
      "id": "7MY2z-L7PXPE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_update(index, value):\n",
        "    update_latent(index, value)"
      ],
      "metadata": {
        "id": "F6ho1savPVWF"
      },
      "id": "F6ho1savPVWF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b29be398",
      "metadata": {
        "id": "b29be398"
      },
      "outputs": [],
      "source": [
        "interact(interactive_update, index=index_slider, value=value_slider)"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}