{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "D5yFz-6HXVQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "6ZrOuE-NW_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"ambityga/imagenet100\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "HGBatKFKutJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l $path/val.X/n01773549"
      ],
      "metadata": {
        "id": "PQhrNEdVu4DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagepath = path + '/val.X/' + 'n01773549' +'/' + 'ILSVRC2012_val_00008316.JPEG'"
      ],
      "metadata": {
        "id": "l0zeZwsYvNgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(imagepath)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "vXyx3TxskzxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "vitb8 = torch.hub.load('facebookresearch/dino:main', 'dino_vitb8')"
      ],
      "metadata": {
        "id": "qCW_l3Eor2jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vitb8.eval()"
      ],
      "metadata": {
        "id": "4q8eK8xUsAkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "print(image.shape)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB\n",
        "image_size = (224, 224)\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0/255, image_size, swapRB=True, crop=False)\n",
        "blob[0][0] = (blob[0][0] - 0.485)/0.229\n",
        "blob[0][1] = (blob[0][1] - 0.456)/0.224\n",
        "blob[0][2] = (blob[0][2] - 0.406)/0.225\n",
        "x = torch.tensor(blob) # 1 x 3 x 224 x 224\n",
        "print(x.min().item(),x.max().item())"
      ],
      "metadata": {
        "id": "h0-MYUhWr6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed\n",
        "B, _, h, w = x.shape\n",
        "x = vitb8.patch_embed(x)  # patch linear embedding by Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
        "print(x.shape) # 1 x 784 x 768   # 784 = 28 x 28, 224 = 28 x 8, 768 = 12 x 64"
      ],
      "metadata": {
        "id": "1z832boLsU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add CLS\n",
        "cls_tokens = vitb8.cls_token.expand(B, -1, -1)\n",
        "x = torch.cat((cls_tokens, x), dim=1) # 1 x 785 x 768"
      ],
      "metadata": {
        "id": "hTGe-VD3sd1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add positional encoding\n",
        "x = x + vitb8.interpolate_pos_encoding(x, h, w) # 1 x 785 x 768"
      ],
      "metadata": {
        "id": "uQOP9HfMskPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode\n",
        "attn_maps = []\n",
        "for block in vitb8.blocks:\n",
        "    y, attn = block.attn(block.norm1(x))\n",
        "    attn_maps.append(attn)\n",
        "    x += y\n",
        "    x += block.mlp(block.norm2(x))\n",
        "\n",
        "x = vitb8.norm(x) # 1 x 785 x 768"
      ],
      "metadata": {
        "id": "3AseQx6as2SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wipeout\n",
        "features = x[:, 0] # 1 x 768\n",
        "print(features.shape)\n",
        "print(features)"
      ],
      "metadata": {
        "id": "h56md8QGtVtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_mats.shape"
      ],
      "metadata": {
        "id": "o9FEqnIuw3iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize attention maps\n",
        "attn_mat = torch.stack(attn_maps).squeeze(1) # 12 x 12 x 785 x 785\n",
        "grid_size = int(np.sqrt(attn_mat.size(-1)))\n",
        "rows = []\n",
        "for i, attn_heads in enumerate(attn_mat):\n",
        "    cols = []\n",
        "    for j, attn_head in enumerate(attn_heads):\n",
        "        mask = attn_head[0, 1:].pow(0.5).reshape(grid_size,grid_size).detach().cpu().numpy() # 28 x 28\n",
        "        mask = (np.sqrt(mask)*255).astype(np.uint8)\n",
        "        mask = cv2.resize(mask, (image.shape[1],image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR)\n",
        "        cv2.rectangle(mask,(0,0),(mask.shape[1],mask.shape[0]),(200,0,0),2)\n",
        "        cv2.putText(mask,f'H{j}',(mask.shape[1]*4//10,20),0,0.8,(200,0,0))\n",
        "        cols.append(mask)\n",
        "\n",
        "    row = cv2.hconcat(cols)\n",
        "    cv2.putText(row,f'{i}',(5,20),0,0.8,(0,255,0))\n",
        "    rows.append(row)\n",
        "\n",
        "disp = cv2.vconcat(rows)\n",
        "cv2_imshow(disp)"
      ],
      "metadata": {
        "id": "ZydLbFfvtckI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}