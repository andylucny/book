{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "metadata": {
        "id": "D5yFz-6HXVQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "6ZrOuE-NW_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"ambityga/imagenet100\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "HGBatKFKutJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l $path/val.X/n01773549"
      ],
      "metadata": {
        "id": "PQhrNEdVu4DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagepath = path + '/val.X/' + 'n01773549' +'/' + 'ILSVRC2012_val_00008316.JPEG'"
      ],
      "metadata": {
        "id": "l0zeZwsYvNgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(imagepath)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "vXyx3TxskzxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "vitb8 = torch.hub.load('facebookresearch/dino:main', 'dino_vitb8')"
      ],
      "metadata": {
        "id": "qCW_l3Eor2jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vitb8.eval()"
      ],
      "metadata": {
        "id": "4q8eK8xUsAkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "print(image.shape)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_size = (224, 224)\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0/255, image_size, swapRB=True, crop=False)\n",
        "blob[0][0] = (blob[0][0] - 0.485)/0.229\n",
        "blob[0][1] = (blob[0][1] - 0.456)/0.224\n",
        "blob[0][2] = (blob[0][2] - 0.406)/0.225\n",
        "x = torch.tensor(blob) # 1 x 3 x 224 x 224\n",
        "print(x.min().item(),x.max().item())\n",
        "print(blob.shape)"
      ],
      "metadata": {
        "id": "h0-MYUhWr6IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed\n",
        "B, _, h, w = x.shape\n",
        "x = vitb8.patch_embed(x)  # patch linear embedding by Conv2d(3, 768, kernel_size=(8, 8), stride=(8, 8))\n",
        "print(x.shape) # 1 x 784 x 768   # 784 = 28 x 28, 224 = 28 x 8, 768 = 12 x 64"
      ],
      "metadata": {
        "id": "1z832boLsU_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add CLS\n",
        "cls_tokens = vitb8.cls_token.expand(B, -1, -1)\n",
        "x = torch.cat((cls_tokens, x), dim=1) # 1 x 785 x 768\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "hTGe-VD3sd1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add positional encoding\n",
        "x = x + vitb8.interpolate_pos_encoding(x, h, w) # 1 x 785 x 768"
      ],
      "metadata": {
        "id": "uQOP9HfMskPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode\n",
        "attn_maps = []\n",
        "for block in vitb8.blocks:\n",
        "    y, attn = block.attn(block.norm1(x))\n",
        "    attn_maps.append(attn)\n",
        "    x += y\n",
        "    x += block.mlp(block.norm2(x))\n",
        "\n",
        "x = vitb8.norm(x) # 1 x 785 x 768"
      ],
      "metadata": {
        "id": "3AseQx6as2SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wipeout\n",
        "features = x[:, 0] # 1 x 768\n",
        "print(features.shape)\n",
        "print(features)"
      ],
      "metadata": {
        "id": "h56md8QGtVtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_mask(img, mask):\n",
        "    H, W = img.shape[:2]\n",
        "    mask_resized = cv2.resize(mask, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    if img.ndim == 3:\n",
        "        mask_resized = np.repeat(mask_resized[:, :, None], 3, axis=2)\n",
        "    result = (img.astype(np.float32) * mask_resized).clip(0, 255).astype(np.uint8)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Gr4_36TSO7ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize attention maps\n",
        "base = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "att_mats = torch.stack(attn_maps).squeeze(1) # (12, 12, 50, 50)\n",
        "num_layers, num_heads, N, _ = att_mats.shape\n",
        "grid_size = int(math.sqrt(N-1))\n",
        "plt.figure(figsize=(2 * num_heads, 2 * num_layers))\n",
        "for t in range(num_layers):\n",
        "    for i in range(num_heads):\n",
        "        head = att_mats[t, i]      # shape (50, 50)\n",
        "        mask = head[0, 1:].reshape(grid_size, grid_size)\n",
        "        mask /= mask.max()\n",
        "        mask = mask.detach().cpu().numpy()\n",
        "        disp = draw_mask(base, mask)\n",
        "        plt.subplot(num_layers, num_heads, t * num_heads + i + 1)\n",
        "        plt.imshow(disp, cmap='gray')\n",
        "        plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2B9SR0BvO9BA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}